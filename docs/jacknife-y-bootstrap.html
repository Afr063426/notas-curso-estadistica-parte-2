<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Capítulo 3 Jacknife y Bootstrap | Notas Curso de Estadística</title>
  <meta name="description" content="Capítulo 3 Jacknife y Bootstrap | Notas Curso de Estadística" />
  <meta name="generator" content="bookdown 0.21 and GitBook 2.6.7" />

  <meta property="og:title" content="Capítulo 3 Jacknife y Bootstrap | Notas Curso de Estadística" />
  <meta property="og:type" content="book" />
  
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Capítulo 3 Jacknife y Bootstrap | Notas Curso de Estadística" />
  
  
  

<meta name="author" content="Maikol Solís Chacón y Luis Barboza Chichilla" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="estimación-de-densidades.html"/>
<link rel="next" href="estimación-de-densidades-con-bayes.html"/>
<script src="libs/header-attrs-2.6/header-attrs.js"></script>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />











<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Curso de Estadística</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Introducción</a></li>
<li class="chapter" data-level="2" data-path="estimación-de-densidades.html"><a href="estimación-de-densidades.html"><i class="fa fa-check"></i><b>2</b> Estimación de densidades</a>
<ul>
<li class="chapter" data-level="2.1" data-path="estimación-de-densidades.html"><a href="estimación-de-densidades.html#histograma"><i class="fa fa-check"></i><b>2.1</b> Histograma</a>
<ul>
<li class="chapter" data-level="2.1.1" data-path="estimación-de-densidades.html"><a href="estimación-de-densidades.html#construcción-estadística"><i class="fa fa-check"></i><b>2.1.1</b> Construcción Estadística</a></li>
<li class="chapter" data-level="2.1.2" data-path="estimación-de-densidades.html"><a href="estimación-de-densidades.html#construcción-probabilistica"><i class="fa fa-check"></i><b>2.1.2</b> Construcción probabilistica</a></li>
<li class="chapter" data-level="2.1.3" data-path="estimación-de-densidades.html"><a href="estimación-de-densidades.html#propiedades-estadísticas"><i class="fa fa-check"></i><b>2.1.3</b> Propiedades estadísticas</a></li>
<li class="chapter" data-level="2.1.4" data-path="estimación-de-densidades.html"><a href="estimación-de-densidades.html#sesgo"><i class="fa fa-check"></i><b>2.1.4</b> Sesgo</a></li>
<li class="chapter" data-level="2.1.5" data-path="estimación-de-densidades.html"><a href="estimación-de-densidades.html#varianza"><i class="fa fa-check"></i><b>2.1.5</b> Varianza</a></li>
<li class="chapter" data-level="2.1.6" data-path="estimación-de-densidades.html"><a href="estimación-de-densidades.html#error-cuadrático-medio"><i class="fa fa-check"></i><b>2.1.6</b> Error cuadrático medio</a></li>
<li class="chapter" data-level="2.1.7" data-path="estimación-de-densidades.html"><a href="estimación-de-densidades.html#error-cuadrático-medio-integrado"><i class="fa fa-check"></i><b>2.1.7</b> Error cuadrático medio integrado</a></li>
<li class="chapter" data-level="2.1.8" data-path="estimación-de-densidades.html"><a href="estimación-de-densidades.html#ancho-de-banda-óptimo-para-el-histograma"><i class="fa fa-check"></i><b>2.1.8</b> Ancho de banda óptimo para el histograma</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="estimación-de-densidades.html"><a href="estimación-de-densidades.html#estimación-no-paramétrica-de-densidad"><i class="fa fa-check"></i><b>2.2</b> Estimación No-paramétrica de densidad</a>
<ul>
<li class="chapter" data-level="2.2.1" data-path="estimación-de-densidades.html"><a href="estimación-de-densidades.html#primera-construcción"><i class="fa fa-check"></i><b>2.2.1</b> Primera construcción</a></li>
<li class="chapter" data-level="2.2.2" data-path="estimación-de-densidades.html"><a href="estimación-de-densidades.html#otra-construcción"><i class="fa fa-check"></i><b>2.2.2</b> Otra construcción</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="estimación-de-densidades.html"><a href="estimación-de-densidades.html#propiedades-estadísticas-1"><i class="fa fa-check"></i><b>2.3</b> Propiedades Estadísticas</a>
<ul>
<li class="chapter" data-level="2.3.1" data-path="estimación-de-densidades.html"><a href="estimación-de-densidades.html#varianza-1"><i class="fa fa-check"></i><b>2.3.1</b> Varianza</a></li>
<li class="chapter" data-level="2.3.2" data-path="estimación-de-densidades.html"><a href="estimación-de-densidades.html#sesgo-1"><i class="fa fa-check"></i><b>2.3.2</b> Sesgo</a></li>
<li class="chapter" data-level="2.3.3" data-path="estimación-de-densidades.html"><a href="estimación-de-densidades.html#error-cuadrático-medio-y-error-cuadrático-medio-integrado"><i class="fa fa-check"></i><b>2.3.3</b> Error cuadrático medio y Error cuadrático medio integrado</a></li>
<li class="chapter" data-level="2.3.4" data-path="estimación-de-densidades.html"><a href="estimación-de-densidades.html#ancho-de-banda-óptimo"><i class="fa fa-check"></i><b>2.3.4</b> Ancho de banda óptimo</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="estimación-de-densidades.html"><a href="estimación-de-densidades.html#escogiendo-el-ancho-de-banda"><i class="fa fa-check"></i><b>2.4</b> Escogiendo el ancho de banda</a>
<ul>
<li class="chapter" data-level="2.4.1" data-path="estimación-de-densidades.html"><a href="estimación-de-densidades.html#referencia-normal"><i class="fa fa-check"></i><b>2.4.1</b> Referencia normal</a></li>
<li class="chapter" data-level="2.4.2" data-path="estimación-de-densidades.html"><a href="estimación-de-densidades.html#validación-cruzada"><i class="fa fa-check"></i><b>2.4.2</b> Validación Cruzada</a></li>
<li class="chapter" data-level="2.4.3" data-path="estimación-de-densidades.html"><a href="estimación-de-densidades.html#intervalos-de-confianza-para-estimadores-de-densidad-no-paramétricos"><i class="fa fa-check"></i><b>2.4.3</b> Intervalos de confianza para estimadores de densidad no paramétricos</a></li>
</ul></li>
<li class="chapter" data-level="2.5" data-path="estimación-de-densidades.html"><a href="estimación-de-densidades.html#laboratorio"><i class="fa fa-check"></i><b>2.5</b> Laboratorio</a>
<ul>
<li class="chapter" data-level="2.5.1" data-path="estimación-de-densidades.html"><a href="estimación-de-densidades.html#efecto-de-distintos-kernels-en-la-estimación"><i class="fa fa-check"></i><b>2.5.1</b> Efecto de distintos Kernels en la estimación</a></li>
<li class="chapter" data-level="2.5.2" data-path="estimación-de-densidades.html"><a href="estimación-de-densidades.html#efecto-del-ancho-de-banda-en-la-estimación"><i class="fa fa-check"></i><b>2.5.2</b> Efecto del ancho de banda en la estimación</a></li>
<li class="chapter" data-level="2.5.3" data-path="estimación-de-densidades.html"><a href="estimación-de-densidades.html#ancho-de-banda-óptimo-1"><i class="fa fa-check"></i><b>2.5.3</b> Ancho de banda óptimo</a></li>
<li class="chapter" data-level="2.5.4" data-path="estimación-de-densidades.html"><a href="estimación-de-densidades.html#validación-cruzada-1"><i class="fa fa-check"></i><b>2.5.4</b> Validación cruzada</a></li>
<li class="chapter" data-level="2.5.5" data-path="estimación-de-densidades.html"><a href="estimación-de-densidades.html#temas-adicionales"><i class="fa fa-check"></i><b>2.5.5</b> Temas adicionales</a></li>
</ul></li>
<li class="chapter" data-level="2.6" data-path="estimación-de-densidades.html"><a href="estimación-de-densidades.html#ejercicios"><i class="fa fa-check"></i><b>2.6</b> Ejercicios</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="jacknife-y-bootstrap.html"><a href="jacknife-y-bootstrap.html"><i class="fa fa-check"></i><b>3</b> Jacknife y Bootstrap</a>
<ul>
<li class="chapter" data-level="3.1" data-path="jacknife-y-bootstrap.html"><a href="jacknife-y-bootstrap.html#caso-concreto"><i class="fa fa-check"></i><b>3.1</b> Caso concreto</a></li>
<li class="chapter" data-level="3.2" data-path="jacknife-y-bootstrap.html"><a href="jacknife-y-bootstrap.html#jacknife"><i class="fa fa-check"></i><b>3.2</b> Jacknife</a></li>
<li class="chapter" data-level="3.3" data-path="jacknife-y-bootstrap.html"><a href="jacknife-y-bootstrap.html#bootstrap"><i class="fa fa-check"></i><b>3.3</b> Bootstrap</a></li>
<li class="chapter" data-level="3.4" data-path="jacknife-y-bootstrap.html"><a href="jacknife-y-bootstrap.html#ejercicios-1"><i class="fa fa-check"></i><b>3.4</b> Ejercicios</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="estimación-de-densidades-con-bayes.html"><a href="estimación-de-densidades-con-bayes.html"><i class="fa fa-check"></i><b>4</b> Estimación de densidades con Bayes</a>
<ul>
<li class="chapter" data-level="4.1" data-path="estimación-de-densidades-con-bayes.html"><a href="estimación-de-densidades-con-bayes.html#introducción-a-la-estimación-bayesiana"><i class="fa fa-check"></i><b>4.1</b> Introducción a la estimación Bayesiana</a>
<ul>
<li class="chapter" data-level="4.1.1" data-path="estimación-de-densidades-con-bayes.html"><a href="estimación-de-densidades-con-bayes.html#preliminares"><i class="fa fa-check"></i><b>4.1.1</b> Preliminares</a></li>
<li class="chapter" data-level="4.1.2" data-path="estimación-de-densidades-con-bayes.html"><a href="estimación-de-densidades-con-bayes.html#ejemplo-sencillo"><i class="fa fa-check"></i><b>4.1.2</b> Ejemplo sencillo</a></li>
<li class="chapter" data-level="4.1.3" data-path="estimación-de-densidades-con-bayes.html"><a href="estimación-de-densidades-con-bayes.html#datos-reales"><i class="fa fa-check"></i><b>4.1.3</b> Datos reales</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="estimación-de-densidades-con-bayes.html"><a href="estimación-de-densidades-con-bayes.html#previa-de-histograma"><i class="fa fa-check"></i><b>4.2</b> Previa de histograma</a></li>
<li class="chapter" data-level="4.3" data-path="estimación-de-densidades-con-bayes.html"><a href="estimación-de-densidades-con-bayes.html#métodos-monte-carlo"><i class="fa fa-check"></i><b>4.3</b> Métodos Monte Carlo</a></li>
<li class="chapter" data-level="4.4" data-path="estimación-de-densidades-con-bayes.html"><a href="estimación-de-densidades-con-bayes.html#una-moneda"><i class="fa fa-check"></i><b>4.4</b> Una moneda</a>
<ul>
<li class="chapter" data-level="4.4.1" data-path="estimación-de-densidades-con-bayes.html"><a href="estimación-de-densidades-con-bayes.html#ejemplo-del-viajero"><i class="fa fa-check"></i><b>4.4.1</b> Ejemplo del viajero</a></li>
<li class="chapter" data-level="4.4.2" data-path="estimación-de-densidades-con-bayes.html"><a href="estimación-de-densidades-con-bayes.html#cadenas-de-markov"><i class="fa fa-check"></i><b>4.4.2</b> Cadenas de Markov</a></li>
<li class="chapter" data-level="4.4.3" data-path="estimación-de-densidades-con-bayes.html"><a href="estimación-de-densidades-con-bayes.html#el-algoritmo-de-metropolis-hasting"><i class="fa fa-check"></i><b>4.4.3</b> El algoritmo de Metropolis-Hasting</a></li>
<li class="chapter" data-level="4.4.4" data-path="estimación-de-densidades-con-bayes.html"><a href="estimación-de-densidades-con-bayes.html#por-qué-el-algoritmo-de-metropolis-hasting-funciona"><i class="fa fa-check"></i><b>4.4.4</b> ¿Por qué el algoritmo de Metropolis Hasting funciona?</a></li>
<li class="chapter" data-level="4.4.5" data-path="estimación-de-densidades-con-bayes.html"><a href="estimación-de-densidades-con-bayes.html#extensión-al-caso-del-viajero"><i class="fa fa-check"></i><b>4.4.5</b> Extensión al caso del viajero</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="estimación-de-densidades-con-bayes.html"><a href="estimación-de-densidades-con-bayes.html#dos-monedas"><i class="fa fa-check"></i><b>4.5</b> Dos monedas</a>
<ul>
<li class="chapter" data-level="4.5.1" data-path="estimación-de-densidades-con-bayes.html"><a href="estimación-de-densidades-con-bayes.html#muestreo-de-gibbs"><i class="fa fa-check"></i><b>4.5.1</b> Muestreo de Gibbs</a></li>
</ul></li>
<li class="chapter" data-level="4.6" data-path="estimación-de-densidades-con-bayes.html"><a href="estimación-de-densidades-con-bayes.html#uso-de-jags"><i class="fa fa-check"></i><b>4.6</b> Uso de JAGS</a></li>
<li class="chapter" data-level="4.7" data-path="estimación-de-densidades-con-bayes.html"><a href="estimación-de-densidades-con-bayes.html#uso-de-stan"><i class="fa fa-check"></i><b>4.7</b> Uso de STAN</a></li>
<li class="chapter" data-level="4.8" data-path="estimación-de-densidades-con-bayes.html"><a href="estimación-de-densidades-con-bayes.html#ejercicios-2"><i class="fa fa-check"></i><b>4.8</b> Ejercicios</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="métodos-lineares-de-regresión.html"><a href="métodos-lineares-de-regresión.html"><i class="fa fa-check"></i><b>5</b> Métodos lineares de regresión</a>
<ul>
<li class="chapter" data-level="5.1" data-path="métodos-lineares-de-regresión.html"><a href="métodos-lineares-de-regresión.html#introducción-1"><i class="fa fa-check"></i><b>5.1</b> Introducción</a></li>
<li class="chapter" data-level="5.2" data-path="métodos-lineares-de-regresión.html"><a href="métodos-lineares-de-regresión.html#regresión-lineal"><i class="fa fa-check"></i><b>5.2</b> Regresión lineal</a>
<ul>
<li class="chapter" data-level="5.2.1" data-path="métodos-lineares-de-regresión.html"><a href="métodos-lineares-de-regresión.html#forma-matricial"><i class="fa fa-check"></i><b>5.2.1</b> Forma matricial</a></li>
<li class="chapter" data-level="5.2.2" data-path="métodos-lineares-de-regresión.html"><a href="métodos-lineares-de-regresión.html#laboratorio-1"><i class="fa fa-check"></i><b>5.2.2</b> Laboratorio</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="métodos-lineares-de-regresión.html"><a href="métodos-lineares-de-regresión.html#propiedades-estadísticas-2"><i class="fa fa-check"></i><b>5.3</b> Propiedades estadísticas</a>
<ul>
<li class="chapter" data-level="5.3.1" data-path="métodos-lineares-de-regresión.html"><a href="métodos-lineares-de-regresión.html#prueba-t"><i class="fa fa-check"></i><b>5.3.1</b> Prueba <span class="math inline">\(t\)</span></a></li>
<li class="chapter" data-level="5.3.2" data-path="métodos-lineares-de-regresión.html"><a href="métodos-lineares-de-regresión.html#prueba-f"><i class="fa fa-check"></i><b>5.3.2</b> Prueba <span class="math inline">\(F\)</span></a></li>
<li class="chapter" data-level="5.3.3" data-path="métodos-lineares-de-regresión.html"><a href="métodos-lineares-de-regresión.html#laboratorio-2"><i class="fa fa-check"></i><b>5.3.3</b> Laboratorio</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="métodos-lineares-de-regresión.html"><a href="métodos-lineares-de-regresión.html#medida-de-bondad-de-ajuste"><i class="fa fa-check"></i><b>5.4</b> Medida de bondad de ajuste</a>
<ul>
<li class="chapter" data-level="5.4.1" data-path="métodos-lineares-de-regresión.html"><a href="métodos-lineares-de-regresión.html#laboratorio-3"><i class="fa fa-check"></i><b>5.4.1</b> Laboratorio</a></li>
</ul></li>
<li class="chapter" data-level="5.5" data-path="métodos-lineares-de-regresión.html"><a href="métodos-lineares-de-regresión.html#predicción"><i class="fa fa-check"></i><b>5.5</b> Predicción</a>
<ul>
<li class="chapter" data-level="5.5.1" data-path="métodos-lineares-de-regresión.html"><a href="métodos-lineares-de-regresión.html#laboratorio-4"><i class="fa fa-check"></i><b>5.5.1</b> Laboratorio</a></li>
</ul></li>
<li class="chapter" data-level="5.6" data-path="métodos-lineares-de-regresión.html"><a href="métodos-lineares-de-regresión.html#interacciones"><i class="fa fa-check"></i><b>5.6</b> Interacciones</a>
<ul>
<li class="chapter" data-level="5.6.1" data-path="métodos-lineares-de-regresión.html"><a href="métodos-lineares-de-regresión.html#laboratorio-5"><i class="fa fa-check"></i><b>5.6.1</b> Laboratorio</a></li>
</ul></li>
<li class="chapter" data-level="5.7" data-path="métodos-lineares-de-regresión.html"><a href="métodos-lineares-de-regresión.html#hipotesis-en-regresión-lineal"><i class="fa fa-check"></i><b>5.7</b> Hipotesis en regresión lineal</a>
<ul>
<li class="chapter" data-level="5.7.1" data-path="métodos-lineares-de-regresión.html"><a href="métodos-lineares-de-regresión.html#hipotésis"><i class="fa fa-check"></i><b>5.7.1</b> Hipotésis</a></li>
<li class="chapter" data-level="5.7.2" data-path="métodos-lineares-de-regresión.html"><a href="métodos-lineares-de-regresión.html#chequeos-básicos-de-las-hipótesis-de-regresión-lineal"><i class="fa fa-check"></i><b>5.7.2</b> Chequeos básicos de las hipótesis de regresión lineal</a></li>
<li class="chapter" data-level="5.7.3" data-path="métodos-lineares-de-regresión.html"><a href="métodos-lineares-de-regresión.html#otros-chequeos-importantes"><i class="fa fa-check"></i><b>5.7.3</b> Otros chequeos importantes</a></li>
</ul></li>
<li class="chapter" data-level="5.8" data-path="métodos-lineares-de-regresión.html"><a href="métodos-lineares-de-regresión.html#ejercicios-3"><i class="fa fa-check"></i><b>5.8</b> Ejercicios</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="regresión-logística.html"><a href="regresión-logística.html"><i class="fa fa-check"></i><b>6</b> Regresión Logística</a>
<ul>
<li class="chapter" data-level="6.1" data-path="regresión-logística.html"><a href="regresión-logística.html#razón-de-proporción"><i class="fa fa-check"></i><b>6.1</b> Razón de proporción</a></li>
<li class="chapter" data-level="6.2" data-path="regresión-logística.html"><a href="regresión-logística.html#máxima-verosimilitud"><i class="fa fa-check"></i><b>6.2</b> Máxima verosimilitud</a>
<ul>
<li class="chapter" data-level="6.2.1" data-path="regresión-logística.html"><a href="regresión-logística.html#residuos"><i class="fa fa-check"></i><b>6.2.1</b> Residuos</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="regresión-logística.html"><a href="regresión-logística.html#diágnosticos-del-modelo"><i class="fa fa-check"></i><b>6.3</b> Diágnosticos del modelo</a>
<ul>
<li class="chapter" data-level="6.3.1" data-path="regresión-logística.html"><a href="regresión-logística.html#supuesto-de-linealidad"><i class="fa fa-check"></i><b>6.3.1</b> Supuesto de linealidad</a></li>
<li class="chapter" data-level="6.3.2" data-path="regresión-logística.html"><a href="regresión-logística.html#valor-de-gran-influencia"><i class="fa fa-check"></i><b>6.3.2</b> Valor de gran influencia</a></li>
<li class="chapter" data-level="6.3.3" data-path="regresión-logística.html"><a href="regresión-logística.html#multicolinealidad-1"><i class="fa fa-check"></i><b>6.3.3</b> Multicolinealidad</a></li>
</ul></li>
<li class="chapter" data-level="6.4" data-path="regresión-logística.html"><a href="regresión-logística.html#predicción-y-poder-de-clasificación"><i class="fa fa-check"></i><b>6.4</b> Predicción y poder de clasificación</a>
<ul>
<li class="chapter" data-level="6.4.1" data-path="regresión-logística.html"><a href="regresión-logística.html#curva-roc"><i class="fa fa-check"></i><b>6.4.1</b> Curva ROC</a></li>
</ul></li>
<li class="chapter" data-level="6.5" data-path="regresión-logística.html"><a href="regresión-logística.html#ejercicios-4"><i class="fa fa-check"></i><b>6.5</b> Ejercicios</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="métodos-de-selección-de-variables.html"><a href="métodos-de-selección-de-variables.html"><i class="fa fa-check"></i><b>7</b> Métodos de selección de variables</a>
<ul>
<li class="chapter" data-level="7.1" data-path="métodos-de-selección-de-variables.html"><a href="métodos-de-selección-de-variables.html#selección-del-mejor-subconjunto."><i class="fa fa-check"></i><b>7.1</b> Selección del mejor subconjunto.</a>
<ul>
<li class="chapter" data-level="7.1.1" data-path="métodos-de-selección-de-variables.html"><a href="métodos-de-selección-de-variables.html#error-de-prueba"><i class="fa fa-check"></i><b>7.1.1</b> Error de prueba</a></li>
<li class="chapter" data-level="7.1.2" data-path="métodos-de-selección-de-variables.html"><a href="métodos-de-selección-de-variables.html#otras-medidas-de-error-de-entrenamiento"><i class="fa fa-check"></i><b>7.1.2</b> Otras medidas de error de entrenamiento</a></li>
<li class="chapter" data-level="7.1.3" data-path="métodos-de-selección-de-variables.html"><a href="métodos-de-selección-de-variables.html#selección-de-modelos-hacia-adelante-forward-stepwise-selection"><i class="fa fa-check"></i><b>7.1.3</b> Selección de modelos hacia adelante (<strong>Forward Stepwise Selection</strong>)</a></li>
<li class="chapter" data-level="7.1.4" data-path="métodos-de-selección-de-variables.html"><a href="métodos-de-selección-de-variables.html#selección-de-modelos-hacia-atrás-backward-stepwise-selection"><i class="fa fa-check"></i><b>7.1.4</b> Selección de modelos hacia atrás (<strong>Backward Stepwise Selection</strong>)</a></li>
</ul></li>
<li class="chapter" data-level="7.2" data-path="métodos-de-selección-de-variables.html"><a href="métodos-de-selección-de-variables.html#métodos-de-regularización"><i class="fa fa-check"></i><b>7.2</b> Métodos de regularización</a>
<ul>
<li class="chapter" data-level="7.2.1" data-path="métodos-de-selección-de-variables.html"><a href="métodos-de-selección-de-variables.html#regresión-ridge"><i class="fa fa-check"></i><b>7.2.1</b> Regresión Ridge</a></li>
<li class="chapter" data-level="7.2.2" data-path="métodos-de-selección-de-variables.html"><a href="métodos-de-selección-de-variables.html#regresión-lasso"><i class="fa fa-check"></i><b>7.2.2</b> Regresión Lasso</a></li>
<li class="chapter" data-level="7.2.3" data-path="métodos-de-selección-de-variables.html"><a href="métodos-de-selección-de-variables.html#explicación-gráfica"><i class="fa fa-check"></i><b>7.2.3</b> Explicación gráfica</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="métodos-de-selección-de-variables.html"><a href="métodos-de-selección-de-variables.html#laboratorio-6"><i class="fa fa-check"></i><b>7.3</b> Laboratorio</a>
<ul>
<li class="chapter" data-level="7.3.1" data-path="métodos-de-selección-de-variables.html"><a href="métodos-de-selección-de-variables.html#cross-validation"><i class="fa fa-check"></i><b>7.3.1</b> Cross-Validation</a></li>
<li class="chapter" data-level="7.3.2" data-path="métodos-de-selección-de-variables.html"><a href="métodos-de-selección-de-variables.html#selección-de-variables"><i class="fa fa-check"></i><b>7.3.2</b> Selección de variables</a></li>
<li class="chapter" data-level="7.3.3" data-path="métodos-de-selección-de-variables.html"><a href="métodos-de-selección-de-variables.html#regresión-lasso-1"><i class="fa fa-check"></i><b>7.3.3</b> Regresión Lasso</a></li>
</ul></li>
<li class="chapter" data-level="7.4" data-path="métodos-de-selección-de-variables.html"><a href="métodos-de-selección-de-variables.html#ejercicios-5"><i class="fa fa-check"></i><b>7.4</b> Ejercicios</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="análisis-en-componentes-principales.html"><a href="análisis-en-componentes-principales.html"><i class="fa fa-check"></i><b>8</b> Análisis en componentes principales</a>
<ul>
<li class="chapter" data-level="8.1" data-path="análisis-en-componentes-principales.html"><a href="análisis-en-componentes-principales.html#representación-gráfica"><i class="fa fa-check"></i><b>8.1</b> Representación gráfica</a></li>
<li class="chapter" data-level="8.2" data-path="análisis-en-componentes-principales.html"><a href="análisis-en-componentes-principales.html#primer-componente-principal"><i class="fa fa-check"></i><b>8.2</b> Primer componente principal</a></li>
<li class="chapter" data-level="8.3" data-path="análisis-en-componentes-principales.html"><a href="análisis-en-componentes-principales.html#segunda-componente-principal"><i class="fa fa-check"></i><b>8.3</b> Segunda componente principal</a></li>
<li class="chapter" data-level="8.4" data-path="análisis-en-componentes-principales.html"><a href="análisis-en-componentes-principales.html#circulo-de-correlaciones"><i class="fa fa-check"></i><b>8.4</b> Circulo de correlaciones</a></li>
<li class="chapter" data-level="8.5" data-path="análisis-en-componentes-principales.html"><a href="análisis-en-componentes-principales.html#volvamos-a-nuestro-ejemplo"><i class="fa fa-check"></i><b>8.5</b> Volvamos a nuestro ejemplo</a></li>
<li class="chapter" data-level="8.6" data-path="análisis-en-componentes-principales.html"><a href="análisis-en-componentes-principales.html#cuántos-componentes-usar"><i class="fa fa-check"></i><b>8.6</b> ¿Cuántos componentes usar?</a></li>
<li class="chapter" data-level="8.7" data-path="análisis-en-componentes-principales.html"><a href="análisis-en-componentes-principales.html#laboratorio-7"><i class="fa fa-check"></i><b>8.7</b> Laboratorio</a></li>
<li class="chapter" data-level="8.8" data-path="análisis-en-componentes-principales.html"><a href="análisis-en-componentes-principales.html#ejercicios-6"><i class="fa fa-check"></i><b>8.8</b> Ejercicios</a></li>
</ul></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Notas Curso de Estadística</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="jacknife-y-bootstrap" class="section level1" number="3">
<h1><span class="header-section-number">Capítulo 3</span> Jacknife y Bootstrap</h1>
<p>Suponga que se quiere estimar un intervalo de confianza para la media
<span class="math inline">\(\mu\)</span> desconocida de un conjunto de datos <span class="math inline">\(X_{1},\ldots, X_{n}\)</span>
que tiene distribución <span class="math inline">\(\mathcal{N}\left(\mu ,\sigma^{2}\right)\)</span>.</p>
<p>Primero se conoce que</p>
<p><span class="math display">\[\begin{equation*}
\sqrt{n}\left( \hat{\mu} - \mu \right)
\xrightarrow{\mathcal{L}} \mathcal{N}\left(0,\sigma^{2}\right),
\end{equation*}\]</span></p>
<p>y esto nos permite escribir el intervalo de confianza como</p>
<p><span class="math display">\[\begin{equation*}
\left[ \hat{\mu} - \hat{\sigma}z_{1-\frac{\alpha}{2}} ,
\hat{\mu} + \hat{\sigma}z_{1-\frac{\alpha}{2}}\right]
\end{equation*}\]</span></p>
<p>donde <span class="math inline">\(z_{1-\frac{\alpha}{2}}\)</span> es el cuantil <span class="math inline">\(1-\frac{\alpha}{2}\)</span>
de una normal estándar.</p>
<p>La expresión anterior es posible ya que el supuesto es que la
distribución de <span class="math inline">\(\hat{\theta}\)</span> es normal.</p>

<div class="remark">
<p> <span class="remark"><em>Nota: </em></span> ¿Qué pasaría si este supuesto es falso o al menos no conocemos la
distribución de <span class="math inline">\(\hat{\theta}\)</span>?</p>
¿Cómo podemos encontrar ese intervalo de confianza?
</div>

<div class="remark">
 <span class="remark"><em>Nota: </em></span> Para una muestra fija, el estimador anterior <span class="math inline">\(\hat{\mu}\)</span>
solamente un valor. No se conoce la distribución de <span class="math inline">\(\hat{\mu}\)</span>. Lo
único que se puede estimar son valores puntuales como la media,
varianza, mediana, etc, pero no sabemos nada de su distribución.
</div>
<div id="caso-concreto" class="section level2" number="3.1">
<h2><span class="header-section-number">3.1</span> Caso concreto</h2>
<p>Suponga que tenemos la siguiente tabla de datos, que representa una
muestra de tiempos y distancias de viajes en Atlanta.</p>
<p>Cargamos la base de la siguiente forma:</p>
<div class="sourceCode" id="cb41"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb41-1"><a href="jacknife-y-bootstrap.html#cb41-1" aria-hidden="true" tabindex="-1"></a>CommuteAtlanta <span class="ot">&lt;-</span> <span class="fu">read.csv2</span>(<span class="st">&quot;data/CommuteAtlanta.csv&quot;</span>)</span></code></pre></div>
<table>
<thead>
<tr class="header">
<th align="left">City</th>
<th align="right">Age</th>
<th align="right">Distance</th>
<th align="right">Time</th>
<th align="left">Sex</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Atlanta</td>
<td align="right">19</td>
<td align="right">10</td>
<td align="right">15</td>
<td align="left">M</td>
</tr>
<tr class="even">
<td align="left">Atlanta</td>
<td align="right">55</td>
<td align="right">45</td>
<td align="right">60</td>
<td align="left">M</td>
</tr>
<tr class="odd">
<td align="left">Atlanta</td>
<td align="right">48</td>
<td align="right">12</td>
<td align="right">45</td>
<td align="left">M</td>
</tr>
<tr class="even">
<td align="left">Atlanta</td>
<td align="right">45</td>
<td align="right">4</td>
<td align="right">10</td>
<td align="left">F</td>
</tr>
<tr class="odd">
<td align="left">Atlanta</td>
<td align="right">48</td>
<td align="right">15</td>
<td align="right">30</td>
<td align="left">F</td>
</tr>
<tr class="even">
<td align="left">Atlanta</td>
<td align="right">43</td>
<td align="right">33</td>
<td align="right">60</td>
<td align="left">M</td>
</tr>
</tbody>
</table>
<p>Para este ejemplo tomaremos la variable  que la
llamaremos  para ser más breves. En este caso note que</p>
<div class="sourceCode" id="cb42"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb42-1"><a href="jacknife-y-bootstrap.html#cb42-1" aria-hidden="true" tabindex="-1"></a>x <span class="ot">&lt;-</span> CommuteAtlanta<span class="sc">$</span>Time</span></code></pre></div>
<p>La media es 29.11 y su varianza 429.2483968. Para efectos de lo que sigue, asignaremos la varianza a la variable <span class="math inline">\(T_n\)</span></p>
<div class="sourceCode" id="cb43"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb43-1"><a href="jacknife-y-bootstrap.html#cb43-1" aria-hidden="true" tabindex="-1"></a>Tn <span class="ot">&lt;-</span> <span class="fu">var</span>(x)</span></code></pre></div>
<p>A partir de estos dos valores, ¿Cuál sería un intervalo de confianza
para la media?</p>
<p>Note que esta pregunta es difícil ya que no tenemos ningún tipo de
información adicional.</p>
<p>Las dos técnicas que veremos a continuación nos permitirán extraer
<em>información adicional</em> de la muestra.</p>

<div class="remark">
 <span class="remark"><em>Nota: </em></span> Para efectos de este capítulo, llamaremos <span class="math inline">\(T_{n}=T\left(  X_{1},\ldots,X_{n}\right)\)</span> al estadístico formado por la muestra de
los <span class="math inline">\(X_{i}\)</span>’s.
</div>
</div>
<div id="jacknife" class="section level2" number="3.2">
<h2><span class="header-section-number">3.2</span> Jacknife</h2>
<p>Esta técnica fue propuesta por  y consiste en la
siguiente observación.</p>
<p>Se puede probar que muchos de los estimadores tiene la propiedad que</p>
<p><span class="math display">\[\begin{equation}
\operatorname{Sesgo}\left(T_{n}\right)=\frac{a}{n}+\frac{b}{n^{2}}+O\left(\frac{1}{n^{3}}\right)
\end{equation}\]</span></p>
<p>para algún <span class="math inline">\(a\)</span> and <span class="math inline">\(b\)</span>.</p>
<p>Por ejemplo <span class="math inline">\(\sigma^{2}=\mathrm{Var}\left(X_{i}\right)\)</span> y sea
<span class="math inline">\(\widehat{\sigma}_{n}^{2}=n^{-1} \sum_{i=1}^{n}\left(X_{i}-\right.\)</span>
<span class="math inline">\(\bar{X})^{2}\)</span>. Entonces,</p>
<p><span class="math display">\[\begin{equation*}
\mathbb{E}\left(\widehat{\sigma}_{n}^{2}\right)=
\frac{n-1}{n}\sigma^{2}
\end{equation*}\]</span></p>
<p>por lo tanto</p>
<p><span class="math display">\[\begin{equation*}
\mathrm{Sesgo} = -\frac{\sigma^{2}}{n}
\end{equation*}\]</span></p>
<p>Por lo tanto en este caso <span class="math inline">\(a=-\sigma^{2}\)</span> y <span class="math inline">\(b=0\)</span>.</p>
<p>Defina <span class="math inline">\(T_{(-i)}\)</span> como el estimador <span class="math inline">\(T_{n}\)</span> pero eliminando el
<span class="math inline">\(i\)</span>-ésimo término.</p>
<p>Es claro que en este contexto, se tiene que</p>
<p><span class="math display">\[\begin{equation}
\operatorname{Sesgo}\left(T_{(-i)}\right)=\frac{a}{n-1}+\frac{b}{(n-1)^{2}}+O\left(\frac{1}{(n-1)^{3}}\right)
\end{equation}\]</span></p>

<div class="exercise">
<span id="exr:unnamed-chunk-67" class="exercise"><strong>Ejercicio 3.1  </strong></span>Una forma fácil de construir los <span class="math inline">\(T_{(-i)}\)</span> es primero replicando
la matriz de datos múltiple veces usando el producto de kronecker
</div>
<div class="sourceCode" id="cb44"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb44-1"><a href="jacknife-y-bootstrap.html#cb44-1" aria-hidden="true" tabindex="-1"></a>n <span class="ot">&lt;-</span> <span class="fu">length</span>(x)</span>
<span id="cb44-2"><a href="jacknife-y-bootstrap.html#cb44-2" aria-hidden="true" tabindex="-1"></a>jackdf <span class="ot">&lt;-</span> <span class="fu">kronecker</span>(<span class="fu">matrix</span>(<span class="dv">1</span>, <span class="dv">1</span>, n), x)</span></code></pre></div>
<table>
<tbody>
<tr class="odd">
<td align="right">15</td>
<td align="right">15</td>
<td align="right">15</td>
<td align="right">15</td>
<td align="right">15</td>
<td align="right">15</td>
<td align="right">15</td>
<td align="right">15</td>
<td align="right">15</td>
<td align="right">15</td>
</tr>
<tr class="even">
<td align="right">60</td>
<td align="right">60</td>
<td align="right">60</td>
<td align="right">60</td>
<td align="right">60</td>
<td align="right">60</td>
<td align="right">60</td>
<td align="right">60</td>
<td align="right">60</td>
<td align="right">60</td>
</tr>
<tr class="odd">
<td align="right">45</td>
<td align="right">45</td>
<td align="right">45</td>
<td align="right">45</td>
<td align="right">45</td>
<td align="right">45</td>
<td align="right">45</td>
<td align="right">45</td>
<td align="right">45</td>
<td align="right">45</td>
</tr>
<tr class="even">
<td align="right">10</td>
<td align="right">10</td>
<td align="right">10</td>
<td align="right">10</td>
<td align="right">10</td>
<td align="right">10</td>
<td align="right">10</td>
<td align="right">10</td>
<td align="right">10</td>
<td align="right">10</td>
</tr>
<tr class="odd">
<td align="right">30</td>
<td align="right">30</td>
<td align="right">30</td>
<td align="right">30</td>
<td align="right">30</td>
<td align="right">30</td>
<td align="right">30</td>
<td align="right">30</td>
<td align="right">30</td>
<td align="right">30</td>
</tr>
<tr class="even">
<td align="right">60</td>
<td align="right">60</td>
<td align="right">60</td>
<td align="right">60</td>
<td align="right">60</td>
<td align="right">60</td>
<td align="right">60</td>
<td align="right">60</td>
<td align="right">60</td>
<td align="right">60</td>
</tr>
<tr class="odd">
<td align="right">45</td>
<td align="right">45</td>
<td align="right">45</td>
<td align="right">45</td>
<td align="right">45</td>
<td align="right">45</td>
<td align="right">45</td>
<td align="right">45</td>
<td align="right">45</td>
<td align="right">45</td>
</tr>
<tr class="even">
<td align="right">10</td>
<td align="right">10</td>
<td align="right">10</td>
<td align="right">10</td>
<td align="right">10</td>
<td align="right">10</td>
<td align="right">10</td>
<td align="right">10</td>
<td align="right">10</td>
<td align="right">10</td>
</tr>
<tr class="odd">
<td align="right">25</td>
<td align="right">25</td>
<td align="right">25</td>
<td align="right">25</td>
<td align="right">25</td>
<td align="right">25</td>
<td align="right">25</td>
<td align="right">25</td>
<td align="right">25</td>
<td align="right">25</td>
</tr>
<tr class="even">
<td align="right">15</td>
<td align="right">15</td>
<td align="right">15</td>
<td align="right">15</td>
<td align="right">15</td>
<td align="right">15</td>
<td align="right">15</td>
<td align="right">15</td>
<td align="right">15</td>
<td align="right">15</td>
</tr>
</tbody>
</table>
<p>Y luego se elimina la diagonal</p>
<div class="sourceCode" id="cb45"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb45-1"><a href="jacknife-y-bootstrap.html#cb45-1" aria-hidden="true" tabindex="-1"></a><span class="fu">diag</span>(jackdf) <span class="ot">&lt;-</span> <span class="cn">NA</span></span></code></pre></div>
<table>
<tbody>
<tr class="odd">
<td align="right">NA</td>
<td align="right">15</td>
<td align="right">15</td>
<td align="right">15</td>
<td align="right">15</td>
<td align="right">15</td>
<td align="right">15</td>
<td align="right">15</td>
<td align="right">15</td>
<td align="right">15</td>
</tr>
<tr class="even">
<td align="right">60</td>
<td align="right">NA</td>
<td align="right">60</td>
<td align="right">60</td>
<td align="right">60</td>
<td align="right">60</td>
<td align="right">60</td>
<td align="right">60</td>
<td align="right">60</td>
<td align="right">60</td>
</tr>
<tr class="odd">
<td align="right">45</td>
<td align="right">45</td>
<td align="right">NA</td>
<td align="right">45</td>
<td align="right">45</td>
<td align="right">45</td>
<td align="right">45</td>
<td align="right">45</td>
<td align="right">45</td>
<td align="right">45</td>
</tr>
<tr class="even">
<td align="right">10</td>
<td align="right">10</td>
<td align="right">10</td>
<td align="right">NA</td>
<td align="right">10</td>
<td align="right">10</td>
<td align="right">10</td>
<td align="right">10</td>
<td align="right">10</td>
<td align="right">10</td>
</tr>
<tr class="odd">
<td align="right">30</td>
<td align="right">30</td>
<td align="right">30</td>
<td align="right">30</td>
<td align="right">NA</td>
<td align="right">30</td>
<td align="right">30</td>
<td align="right">30</td>
<td align="right">30</td>
<td align="right">30</td>
</tr>
<tr class="even">
<td align="right">60</td>
<td align="right">60</td>
<td align="right">60</td>
<td align="right">60</td>
<td align="right">60</td>
<td align="right">NA</td>
<td align="right">60</td>
<td align="right">60</td>
<td align="right">60</td>
<td align="right">60</td>
</tr>
<tr class="odd">
<td align="right">45</td>
<td align="right">45</td>
<td align="right">45</td>
<td align="right">45</td>
<td align="right">45</td>
<td align="right">45</td>
<td align="right">NA</td>
<td align="right">45</td>
<td align="right">45</td>
<td align="right">45</td>
</tr>
<tr class="even">
<td align="right">10</td>
<td align="right">10</td>
<td align="right">10</td>
<td align="right">10</td>
<td align="right">10</td>
<td align="right">10</td>
<td align="right">10</td>
<td align="right">NA</td>
<td align="right">10</td>
<td align="right">10</td>
</tr>
<tr class="odd">
<td align="right">25</td>
<td align="right">25</td>
<td align="right">25</td>
<td align="right">25</td>
<td align="right">25</td>
<td align="right">25</td>
<td align="right">25</td>
<td align="right">25</td>
<td align="right">NA</td>
<td align="right">25</td>
</tr>
<tr class="even">
<td align="right">15</td>
<td align="right">15</td>
<td align="right">15</td>
<td align="right">15</td>
<td align="right">15</td>
<td align="right">15</td>
<td align="right">15</td>
<td align="right">15</td>
<td align="right">15</td>
<td align="right">NA</td>
</tr>
</tbody>
</table>
<p>Cada columna contiene toda la muestra excepto el <span class="math inline">\(i\)</span>-ésimo
elemento. Solo basta estimar la media de cada columna:</p>
<div class="sourceCode" id="cb46"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb46-1"><a href="jacknife-y-bootstrap.html#cb46-1" aria-hidden="true" tabindex="-1"></a>T_i <span class="ot">&lt;-</span> <span class="fu">apply</span>(jackdf, <span class="dv">2</span>, var, <span class="at">na.rm =</span> <span class="cn">TRUE</span>)</span></code></pre></div>
<table>
<thead>
<tr class="header">
<th align="right">x</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right">429.7098</td>
</tr>
<tr class="even">
<td align="right">428.1905</td>
</tr>
<tr class="odd">
<td align="right">429.6023</td>
</tr>
<tr class="even">
<td align="right">429.3756</td>
</tr>
<tr class="odd">
<td align="right">430.1087</td>
</tr>
<tr class="even">
<td align="right">428.1905</td>
</tr>
<tr class="odd">
<td align="right">429.6023</td>
</tr>
<tr class="even">
<td align="right">429.3756</td>
</tr>
<tr class="odd">
<td align="right">430.0764</td>
</tr>
<tr class="even">
<td align="right">429.7098</td>
</tr>
</tbody>
</table>
<p>Definamos el sesgo <em>jackife</em> como</p>
<p><span class="math display">\[\begin{equation*}
b_{jack} = (n-1) (\overline{T}_{n} - T_{n})
\end{equation*}\]</span></p>
<p>donde
<span class="math display">\[\begin{equation*}
\overline{T}_{n} = \frac{1}{n} \sum_{i=1}^{n} T_{(-i)}
\end{equation*}\]</span></p>

<div class="exercise">
<span id="exr:unnamed-chunk-71" class="exercise"><strong>Ejercicio 3.2  </strong></span>En nuestro caso tendríamos lo siguiente:
</div>
<div class="sourceCode" id="cb47"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb47-1"><a href="jacknife-y-bootstrap.html#cb47-1" aria-hidden="true" tabindex="-1"></a>(bjack <span class="ot">&lt;-</span> (n <span class="sc">-</span> <span class="dv">1</span>) <span class="sc">*</span> (<span class="fu">mean</span>(T_i) <span class="sc">-</span> Tn))</span></code></pre></div>
<pre><code>## [1] 0</code></pre>
<p>Es decir, que los  generan estimadores de 
que contienen el mismo sesgo.</p>
<p>Observe que <span class="math inline">\(b_{jack}\)</span> tiene la siguiente propiedad</p>
<p><span class="math display">\[\begin{align*}
\mathbb{E}\left(b_{\text {jack}}\right)
&amp;= (n-1)\left(\mathbb{E}\left[\overline{T}_{n}\right] -
\mathbb{E}\left[T_{n}\right]\right) \\
&amp;= (n-1)\left(\mathbb{E}\left[\overline{T}_{n}\right] - \theta +
\theta - \mathbb{E}\left[T_{n}\right]\right) \\
&amp; =(n-1)\left(\mathrm{Sesgo} \left(\overline{T}_{n}\right)
-\mathrm{Sesgo}\left(T_{n}\right)\right) \\
&amp; =(n-1)\left[\left(\frac{1}{n-1}
-\frac{1}{n}\right)
a+\left(\frac{1}{(n-1)^{2}}
-\frac{1}{n^{2}}\right) b+O\left(\frac{1}{n^{3}}\right)\right] \\
&amp; =\frac{a}{n}
+\frac{(2 n-1) b}{n^{2}(n-1)}
+O\left(\frac{1}{n^{2}}\right) \\
&amp; =\operatorname{Sesgo}\left(T_{n}\right)
+O\left(\frac{1}{n^{2}}\right)\\
\end{align*}\]</span></p>

<div class="remark">
 <span class="remark"><em>Nota: </em></span> Es decir, en general, el estimador <span class="math inline">\(b_{\text{jack}}\)</span> aproxima
correctamente <span class="math inline">\(\mathrm{Sesgo}\left( T_{n} \right)\)</span> hasta con un
error del <span class="math inline">\(n^{-2}\)</span>.
</div>
<p>Podemos usar los <span class="math inline">\(T\_i\)</span> para generar muestras adicionales para
estimar el parámetro <span class="math inline">\(\theta\)</span>.</p>
<p>En este caso defina el siguiente estimador:</p>
<p><span class="math display">\[
\widetilde{T}_{i}=n T_{n}-(n-1) T_{(-i)}.
\]</span></p>

<div class="remark">
 <span class="remark"><em>Nota: </em></span> A <span class="math inline">\(\widetilde{T}_{i}\)</span> se le llaman <strong>pseudo-valores</strong> y
representa el aporte o peso que tiene la variable <span class="math inline">\(X_{i}\)</span> para
estimar <span class="math inline">\(T_{n}\)</span>.
</div>

<div class="exercise">
<p><span id="exr:unnamed-chunk-75" class="exercise"><strong>Ejercicio 3.3  </strong></span>Usado un cálculo similar para el <span class="math inline">\(b_{jack}\)</span> pruebe que</p>
<p><span class="math display">\[
\operatorname{Sesgo}\left(T_{\text {jack}
}\right)=-\frac{b}{n(n-1)}+O\left(\frac{1}{n^{2}}\right)=O\left(\frac{1}{n^{2}}\right).
\]</span></p>
¿Qué conclusión se obtiene de este cálculo?
</div>

<div class="exercise">
<span id="exr:unnamed-chunk-76" class="exercise"><strong>Ejercicio 3.4  </strong></span>Los pseudo-valores se estiman de forma directa como,
</div>
<div class="sourceCode" id="cb49"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb49-1"><a href="jacknife-y-bootstrap.html#cb49-1" aria-hidden="true" tabindex="-1"></a>pseudo <span class="ot">&lt;-</span> n <span class="sc">*</span> Tn <span class="sc">-</span> (n <span class="sc">-</span> <span class="dv">1</span>) <span class="sc">*</span> T_i</span>
<span id="cb49-2"><a href="jacknife-y-bootstrap.html#cb49-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-3"><a href="jacknife-y-bootstrap.html#cb49-3" aria-hidden="true" tabindex="-1"></a>pseudo[<span class="dv">1</span><span class="sc">:</span><span class="dv">10</span>]</span></code></pre></div>
<pre><code>##  [1] 199.02972209 957.16225222 252.64417993 365.79679037  -0.06666345
##  [6] 957.16225222 252.64417993 365.79679037  16.09799519 199.02972209</code></pre>
<p>Lo importante acá es notar la similitud que tiene con los datos
reales,</p>
<div class="sourceCode" id="cb51"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb51-1"><a href="jacknife-y-bootstrap.html#cb51-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(<span class="at">x =</span> x, <span class="at">y =</span> pseudo)</span></code></pre></div>
<p><img src="Notas-Curso-Estadistica_files/figure-html/unnamed-chunk-78-1.svg" width="70%" style="display: block; margin: auto;" /></p>
<p>Con estos pseudo-valores, es posible estimar la media y la varianza de
<span class="math inline">\(T_{n}\)</span> con sus respectivos estimadores:</p>
<p><span class="math display">\[
T_{\text {jack }}=\frac{1}{n} \sum_{i=1}^{n} \widetilde{T}_{i}
\]</span></p>
<p>donde</p>
<p><span class="math display">\[
v_{jack}=\frac{\sum_{i=1}^{n}\left(\widetilde{T}_{i}-\frac{1}{n}
\sum_{i=1}^{n} \widetilde{T}_{i}\right)^{2}}{n(n-1)}.
\]</span></p>

<div class="remark">
 <span class="remark"><em>Nota: </em></span> 
Sin embargo, se puede demostrar fácilmente que se pueden usar
pseudovalores para construir una prueba normal de hipótesis. Dado que
cada pseudovalor es independiente e idénticamente distribuido (iid),
se deduce que su promedio se ajusta a una distribución normal a medida
que el tamaño de la muestra aumenta. El promedio de los pseudovalores
es solo <span class="math inline">\(T_ {jack}\)</span> y el valor esperado de ese promedio, debido a la
construcción a la imparcialidad del estimador, es el parámetro bajo
investigación, <span class="math inline">\(\theta\)</span>. Por lo tanto, tenemos que
<span class="math display">\[
  \frac{\sqrt{n}\left(T_{jack}-\theta\right)}{\sqrt{v_{jack}}}
  \rightarrow N(0,1).
\]</span>
</div>

<div class="exercise">
<span id="exr:unnamed-chunk-80" class="exercise"><strong>Ejercicio 3.5  </strong></span>
</div>
<div class="sourceCode" id="cb52"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb52-1"><a href="jacknife-y-bootstrap.html#cb52-1" aria-hidden="true" tabindex="-1"></a>(Tjack <span class="ot">&lt;-</span> <span class="fu">mean</span>(pseudo))</span></code></pre></div>
<pre><code>## [1] 429.2484</code></pre>
<div class="sourceCode" id="cb54"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb54-1"><a href="jacknife-y-bootstrap.html#cb54-1" aria-hidden="true" tabindex="-1"></a>(Vjack <span class="ot">&lt;-</span> <span class="fu">var</span>(pseudo, <span class="at">na.rm =</span> <span class="cn">TRUE</span>))</span></code></pre></div>
<pre><code>## [1] 2701991</code></pre>
<div class="sourceCode" id="cb56"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb56-1"><a href="jacknife-y-bootstrap.html#cb56-1" aria-hidden="true" tabindex="-1"></a>(sdjack <span class="ot">&lt;-</span> <span class="fu">sqrt</span>(Vjack))</span></code></pre></div>
<pre><code>## [1] 1643.774</code></pre>
<div class="sourceCode" id="cb58"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb58-1"><a href="jacknife-y-bootstrap.html#cb58-1" aria-hidden="true" tabindex="-1"></a>(z <span class="ot">&lt;-</span> <span class="fu">qnorm</span>(<span class="dv">1</span> <span class="sc">-</span> <span class="fl">0.05</span><span class="sc">/</span><span class="dv">2</span>))</span></code></pre></div>
<pre><code>## [1] 1.959964</code></pre>
<div class="sourceCode" id="cb60"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb60-1"><a href="jacknife-y-bootstrap.html#cb60-1" aria-hidden="true" tabindex="-1"></a><span class="fu">c</span>(Tjack <span class="sc">-</span> z <span class="sc">*</span> sdjack<span class="sc">/</span><span class="fu">sqrt</span>(n), Tjack <span class="sc">+</span> z <span class="sc">*</span> sdjack<span class="sc">/</span><span class="fu">sqrt</span>(n))</span></code></pre></div>
<pre><code>## [1] 285.1679 573.3289</code></pre>
</div>
<div id="bootstrap" class="section level2" number="3.3">
<h2><span class="header-section-number">3.3</span> Bootstrap</h2>
<p>Este método es un poco más sencillo de implementar que Jacknife y es
igualmente de eficaz propuesto por .</p>
<p>Primero recordemos que estamos estimando una estadístico a partir de
una muestra de modo que <span class="math inline">\(T_{n}=g\left( X_{1},\ldots,X_{n} \right)\)</span>
donde <span class="math inline">\(g\)</span> es cualquier función (media, varianza, quantiles, etc).</p>
<p>Supongamos que conocemos la distribución real de los <span class="math inline">\(X\)</span>’s, llamada <span class="math inline">\(F(x)\)</span>. Si uno
quisiera estimar la varianza de <span class="math inline">\(X\)</span> basta con hacer</p>
<p><span class="math display">\[\begin{equation*}
\mathrm{Var}_{F}\left(T_{n}\right)
= \frac{\sigma^{2}}{n}=\frac{\int x^{2}  dF(x)-\left(\int x
dF(x)\right)^{2}}{n}
\end{equation*}\]</span></p>
<p>donde <span class="math inline">\(\sigma^{2} = \mathrm{Var}\left(X\right)\)</span> y el subindice <span class="math inline">\(F\)</span> es solo para indicar la dependencia con la distribución real.</p>
<p>Ahora dado que no tenemos la distribución real <span class="math inline">\(F(x)\)</span>, una opción es encontrar un estimador de esta llamado <span class="math inline">\(\hat{F}_n\)</span>.</p>
<p>La técnica de boostrap se basa en extraer muchas muestras iid de la distribución <span class="math inline">\(\hat{F}_n\)</span> de modo que se pueda conocer su varianza.</p>
<p>En simple pasos la técnica es</p>
<ol style="list-style-type: decimal">
<li>Seleccione <span class="math inline">\(X_{1}^{*}, \ldots, X_{n}^{*} \sim \widehat{F}_{n}\)</span></li>
<li>Estime <span class="math inline">\(T_{n}^{*}=g\left(X_{1}^{*}, \ldots, X_{n}^{*}\right)\)</span></li>
<li>Repita los Pasos 1 y 2, <span class="math inline">\(B\)</span> veces para obtener <span class="math inline">\(T_{n, 1}^{*}, \ldots, T_{n, B}^{*}\)</span></li>
<li>Estime
<span class="math display">\[
v_{\mathrm{boot}}=\frac{1}{B} \sum_{b=1}^{B}\left(T_{n, b}^{*}-\frac{1}{B} \sum_{r=1}^{B} T_{n, r}^{*}\right)^{2}
\]</span></li>
</ol>
<p>Por la ley de los grandes números tenemos que</p>
<p><span class="math display">\[\begin{equation}
v_{\mathrm{boot}} \stackrel{\mathrm{a.s.}}{\longrightarrow} \mathbb{V}_{\widehat{F}_{n}}\left(T_{n}\right), \text {\quad si } B \rightarrow \infty.
\end{equation}\]</span></p>
<p>además llamaremos,</p>
<p><span class="math display">\[\begin{equation*}
\widehat{\mathrm{se}}_{\mathrm{boot}}=\sqrt{v_{\mathrm{boot}}}
\end{equation*}\]</span></p>
<p>En pocas palabras lo que tenemos es que</p>
<p><span class="math display">\[\begin{align*}
\text  {Mundo Real: }
&amp; F
&amp; \Longrightarrow  X_{1}, \ldots, X_{n}
&amp; \Longrightarrow
&amp; T_{n} = g\left(X_{1}, \ldots, X_{n}\right) \\
\text {Mundo Bootstrap: }
&amp; \widehat{F}_{n}
&amp; \Longrightarrow  X_{1}^{*}, \ldots, X_{n}^{*}
&amp; \Longrightarrow
&amp; T_{n}^{*}=g\left(X_{1}^{*}, \ldots, X_{n}^{*}\right)
\end{align*}\]</span></p>
<p>En términos de convergencia lo que se tiene es que
<span class="math display">\[
\mathrm{Var}_{F}\left(T_{n}\right) \overbrace{\approx}^{O(1 / \sqrt{n})} \mathrm{Var}_{\widehat{F}_{n}}\left(T_{n}\right) \overbrace{\approx}^{O(1 / \sqrt{B})} v_{b o o t}
\]</span></p>

<div class="remark">
 <span class="remark"><em>Nota: </em></span> ¿Cómo extraemos una muestra de <span class="math inline">\(\hat{F}_n\)</span>?
</div>
<p>Recuerden que <span class="math inline">\(\hat{F}_{n}\)</span> asigna la probabilidad de <span class="math inline">\(\frac{1}{n}\)</span> a cada valor usado para construirla.</p>
<p>Por lo tanto, todos los puntos originales <span class="math inline">\(X_{1},\ldots,X_{n}\)</span> tienen probabilidad <span class="math inline">\(\frac{1}{n}\)</span> de ser escogidos, que resulta ser equivalente a un muestreo con remplazo <span class="math inline">\(n\)</span>-veces.</p>
<p>Así que basta cambiar el punto 1. del algoritmo mencionando anteriormente con</p>
<ol style="list-style-type: decimal">
<li>Seleccione una muestra con remplazo <span class="math inline">\(X_{1}^{*}, \ldots, X_{n}^{*}\)</span> de <span class="math inline">\(X_{1},\ldots,X_{n}\)</span>.</li>
</ol>

<div class="exercise">
<p><span id="exr:unnamed-chunk-87" class="exercise"><strong>Ejercicio 3.6  </strong></span>En este ejemplo podemos tomar <span class="math inline">\(B=1000\)</span> y construir esa cantidad de veces nuestro estimador.</p>
</div>
<div class="sourceCode" id="cb62"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb62-1"><a href="jacknife-y-bootstrap.html#cb62-1" aria-hidden="true" tabindex="-1"></a>B <span class="ot">&lt;-</span> <span class="dv">1000</span></span>
<span id="cb62-2"><a href="jacknife-y-bootstrap.html#cb62-2" aria-hidden="true" tabindex="-1"></a>Tboot_b <span class="ot">&lt;-</span> <span class="cn">NULL</span></span>
<span id="cb62-3"><a href="jacknife-y-bootstrap.html#cb62-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb62-4"><a href="jacknife-y-bootstrap.html#cb62-4" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> (b <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>B) {</span>
<span id="cb62-5"><a href="jacknife-y-bootstrap.html#cb62-5" aria-hidden="true" tabindex="-1"></a>    xb <span class="ot">&lt;-</span> <span class="fu">sample</span>(x, <span class="at">size =</span> n, <span class="at">replace =</span> <span class="cn">TRUE</span>)</span>
<span id="cb62-6"><a href="jacknife-y-bootstrap.html#cb62-6" aria-hidden="true" tabindex="-1"></a>    Tboot_b[b] <span class="ot">&lt;-</span> <span class="fu">var</span>(xb)</span>
<span id="cb62-7"><a href="jacknife-y-bootstrap.html#cb62-7" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb62-8"><a href="jacknife-y-bootstrap.html#cb62-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb62-9"><a href="jacknife-y-bootstrap.html#cb62-9" aria-hidden="true" tabindex="-1"></a>Tboot_b[<span class="dv">1</span><span class="sc">:</span><span class="dv">10</span>]</span></code></pre></div>
<pre><code>##  [1] 414.1915 391.2966 310.2777 468.8409 400.5235 380.8023 496.4924 418.5968
##  [9] 461.3902 547.3446</code></pre>
<div class="sourceCode" id="cb64"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb64-1"><a href="jacknife-y-bootstrap.html#cb64-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(Tboot_b)</span></code></pre></div>
<p><img src="Notas-Curso-Estadistica_files/figure-html/unnamed-chunk-89-1.svg" width="70%" style="display: block; margin: auto;" /></p>
<p>Por supuesto podemos encontrar los estadísticos usuales para esta nueva muestra</p>
<div class="sourceCode" id="cb65"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb65-1"><a href="jacknife-y-bootstrap.html#cb65-1" aria-hidden="true" tabindex="-1"></a>(Tboot <span class="ot">&lt;-</span> <span class="fu">mean</span>(Tboot_b))</span></code></pre></div>
<pre><code>## [1] 428.0777</code></pre>
<div class="sourceCode" id="cb67"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb67-1"><a href="jacknife-y-bootstrap.html#cb67-1" aria-hidden="true" tabindex="-1"></a>(Vboot <span class="ot">&lt;-</span> <span class="fu">var</span>(Tboot_b))</span></code></pre></div>
<pre><code>## [1] 5431.092</code></pre>
<div class="sourceCode" id="cb69"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb69-1"><a href="jacknife-y-bootstrap.html#cb69-1" aria-hidden="true" tabindex="-1"></a>(sdboot <span class="ot">&lt;-</span> <span class="fu">sqrt</span>(Vboot))</span></code></pre></div>
<pre><code>## [1] 73.69594</code></pre>
<pre class="```"><code>
### Intervalos de confianza



\subsubsection{Intervalo Normal}

Este es el más sencillo y se escribe como

\begin{equation}
T_{n} \pm z_{\alpha / 2} \widehat{\mathrm{Se}}_{\mathrm{boot}}
\end{equation}

\BeginKnitrBlock{remark}&lt;div class=&quot;remark&quot;&gt;\iffalse{} &lt;span class=&quot;remark&quot;&gt;&lt;em&gt;Nota: &lt;/em&gt;&lt;/span&gt;  \fi{}Este intervalo solo funciona si la distribución de \(T_{n}\) es normal.&lt;/div&gt;\EndKnitrBlock{remark}

\BeginKnitrBlock{exercise}&lt;div class=&quot;exercise&quot;&gt;&lt;span class=&quot;exercise&quot; id=&quot;exr:unnamed-chunk-94&quot;&gt;&lt;strong&gt;(\#exr:unnamed-chunk-94) &lt;/strong&gt;&lt;/span&gt;El cálculo de este intervalo es&lt;/div&gt;\EndKnitrBlock{exercise}

```r
c(Tn - z * sdboot, Tn + z * sdboot)</code></pre>
<pre><code>## [1] 284.8070 573.6898</code></pre>
<pre class="```"><code>
\subsubsection{Intervalo pivotal}

Sea  \(\theta=T(F)\) y  \(\widehat{\theta}_{n}=T\left(\widehat{F}_{n}\right)\) y defina la cantidad pivotal  \(R_{n}=\widehat{\theta}_{n}-\theta .\)

Sea  \(H(r)\) la función de distribución del pivote:
\[
H(r)=\mathbb{P}_{F}\left(R_{n} \leq r\right).
\]

Además considere  \(C_{n}^{\star}=(a, b)\)  donde
\[
a=\widehat{\theta}_{n}-H^{-1}\left(1-\frac{\alpha}{2}\right) \quad \text { y } \quad b=\widehat{\theta}_{n}-H^{-1}\left(\frac{\alpha}{2}\right).
\]

Se sigue que
\begin{align*}
\mathbb{P}(a \leq \theta \leq b)
&amp;=\mathbb{P}\left(\widehat{\theta}_{n}-b \leq R_{n} \leq \widehat{\theta}_{n}-a\right) \\
&amp;=H\left(\widehat{\theta}_{n}-a\right)-H\left(\widehat{\theta}_{n}-b\right) \\
&amp;=H\left(H^{-1}\left(1-\frac{\alpha}{2}\right)\right)-H\left(H^{-1}\left(\frac{\alpha}{2}\right)\right) \\
&amp;=1-\frac{\alpha}{2}-\frac{\alpha}{2}=1-\alpha
\end{align*}
\BeginKnitrBlock{remark}&lt;div class=&quot;remark&quot;&gt;\iffalse{} &lt;span class=&quot;remark&quot;&gt;&lt;em&gt;Nota: &lt;/em&gt;&lt;/span&gt;  \fi{}\(C_{n}^{\star}=(a, b)\)  es un intervalo de confianza al \(1-\alpha\) de confianza.

El problema es que este intervalo depende de \(H\) desconocido.
&lt;/div&gt;\EndKnitrBlock{remark}


Para resolver este problema, se puede construir una versión _bootstrap_ de \(H\) usando lo que sabemos hasta ahora.

\[
\widehat{H}(r)=\frac{1}{B} \sum_{b=1}^{B} I\left(R_{n, b}^{*} \leq r\right)
\]
donde \(R_{n, b}^{*}=\widehat{\theta}_{n, b}^{*}-\widehat{\theta}_{n}\).

Sea  \(r_{\beta}^{*}\) el cuantil muestral de tamaño  \(\beta\) de  \(\left(R_{n, 1}^{*}, \ldots, R_{n, B}^{*}\right)\) y sea \(\theta_{\beta}^{*}\) el cuantil muestral de tamaño  \(\beta\) de \(\left(\theta_{n, 1}^{*}, \ldots, \theta_{n, B}^{*}\right)\).

\BeginKnitrBlock{remark}&lt;div class=&quot;remark&quot;&gt;\iffalse{} &lt;span class=&quot;remark&quot;&gt;&lt;em&gt;Nota: &lt;/em&gt;&lt;/span&gt;  \fi{}Según la notación anterior note que
\begin{equation*}
r_{\beta}^{*}= \theta_{\beta}^{*}-\widehat{\theta}_{n}
\end{equation*}&lt;/div&gt;\EndKnitrBlock{remark}



Con estas observaciones
It follows that an approximate \(1-\alpha\) confidence interval is \(C_{n}=(\widehat{a}, \widehat{b})\) where

\begin{align*}
\widehat{a}
&amp;= \widehat{\theta}_{n}-\widehat{H}^{-1}\left(1-\frac{\alpha}{2}\right)
&amp;= \widehat{\theta}_{n}-r_{1-\alpha / 2}^{*}
&amp;= \widehat{\theta}_{n}-\theta_{1-\alpha / 2}^{*} + \widehat{\theta}_{n}
&amp;=2 \widehat{\theta}_{n}-\theta_{1-\alpha / 2}^{*} \\
\widehat{b} &amp;=\widehat{\theta}_{n}-\widehat{H}^{-1}\left(\frac{\alpha}{2}\right)
&amp;=\widehat{\theta}_{n}-r_{\alpha / 2}^{*}
&amp;= \widehat{\theta}_{n}-\theta_{\alpha / 2}^{*} + \widehat{\theta}_{n}
&amp;=2 \widehat{\theta}_{n}-\theta_{\alpha / 2}^{*}
\end{align*}

\BeginKnitrBlock{remark}&lt;div class=&quot;remark&quot;&gt;\iffalse{} &lt;span class=&quot;remark&quot;&gt;&lt;em&gt;Nota: &lt;/em&gt;&lt;/span&gt;  \fi{}El intervalo de confianza pivotal de tamaño \(1-\alpha\) es
\[
  C_{n}=\left(2 \widehat{\theta}_{n}-\widehat{\theta}_{((1-\alpha / 2) B)}^{*}, 2 \widehat{\theta}_{n}-\widehat{\theta}_{((\alpha / 2) B)}^{*}\right)
  \]&lt;/div&gt;\EndKnitrBlock{remark}

\BeginKnitrBlock{exercise}&lt;div class=&quot;exercise&quot;&gt;&lt;span class=&quot;exercise&quot; id=&quot;exr:unnamed-chunk-99&quot;&gt;&lt;strong&gt;(\#exr:unnamed-chunk-99) &lt;/strong&gt;&lt;/span&gt;El intervalo anterior para un nivel de 95\% se estima de la siguiente forma&lt;/div&gt;\EndKnitrBlock{exercise}

```r
c(2 * Tn - quantile(Tboot_b, 1 - 0.05/2), 2 * Tn - 
    quantile(Tboot_b, 0.05/2))</code></pre>
<pre><code>##    97.5%     2.5% 
## 267.5099 556.9997</code></pre>
<pre class="```"><code>
### Intervalo pivotal studentizado

Una mejora del intervalo anterior sería normalizar los estimadores previamente

\[
Z_{n}=\frac{T_{n}-\theta}{\widehat{\mathrm{se}}_{\mathrm{boot}}}.
\]
Como \(\theta\) es desconocido, entonces la versión a estimar es
\[
Z_{n, b}^{*}=\frac{T_{n, b}^{*}-T_{n}}{\widehat{\mathrm{se}}_{b}^{*}}
\]
donde  \(\widehat{\mathrm{se}}_{b}^{*}\) es un estimador del error estándar de  \(T_{n, b}^{*}\) no de \(T_{n}\).

\BeginKnitrBlock{remark}&lt;div class=&quot;remark&quot;&gt;\iffalse{} &lt;span class=&quot;remark&quot;&gt;&lt;em&gt;Nota: &lt;/em&gt;&lt;/span&gt;  \fi{}Esto requerira estimar la varianza de \(T_{n,b}^*\) para cada \(b\).&lt;/div&gt;\EndKnitrBlock{remark}

Con esto se puede obtener  cantidades \(Z_{n, 1}^{*}, \ldots, Z_{n, B}^{*}\) que debería ser próximos a \(Z_{n}\).

Sea \(z_{\alpha}^{*}\) del \(\alpha\) cuantiĺ de \(Z_{n, 1}^{*}, \ldots, Z_{n, B}^{*},\) entonces  \(\mathbb{P}\left(Z_{n} \leq z_{\alpha}^{*}\right) \approx \alpha\).

Define el intervalo
\begin{equation*}
C_{n}=\left(T_{n}-z_{1-\alpha / 2}^{*} \widehat{\mathrm{se}}_{\mathrm{boot}}, T_{n}-z_{\alpha / 2}^{*} \widehat{\mathrm{se}}_{\mathrm{boot}}\right)
\end{equation*}

Justificado por el siguiente cálculo:


\begin{align*}
\mathbb{P}\left(\theta \in C_{n}\right) &amp;=\mathbb{P}\left(T_{n}-z_{1-\alpha / 2}^{*} \widehat{\mathrm{Se}}_{\mathrm{boot}} \leq \theta \leq T_{n}-z_{\alpha / 2}^{*} \widehat{\mathrm{Se}}_{\mathrm{boot}}\right) \\
&amp;=\mathbb{P}\left(z_{\alpha / 2}^{*} \leq \frac{T_{n}-\theta}{\mathrm{se}_{\mathrm{boot}}} \leq z_{1-\alpha / 2}^{*}\right) \\
&amp;=\mathbb{P}\left(z_{\alpha / 2}^{*} \leq Z_{n} \leq z_{1-\alpha / 2}^{*}\right) \\
&amp; \approx 1-\alpha
\end{align*}

\BeginKnitrBlock{exercise}&lt;div class=&quot;exercise&quot;&gt;&lt;span class=&quot;exercise&quot; id=&quot;exr:unnamed-chunk-102&quot;&gt;&lt;strong&gt;(\#exr:unnamed-chunk-102) &lt;/strong&gt;&lt;/span&gt;
Note que para este caso tenemos que hacer bootstrap para cada estimador bootstrap calculado.&lt;/div&gt;\EndKnitrBlock{exercise}

```r
B &lt;- 1000
Tboot_b &lt;- NULL
Tboot_bm &lt;- NULL
sdboot_b &lt;- NULL

for (b in 1:B) {
    xb &lt;- sample(x, size = n, replace = TRUE)
    Tboot_b[b] &lt;- var(xb)
    for (m in 1:B) {
        xbm &lt;- sample(xb, size = n, replace = TRUE)
        Tboot_bm[m] &lt;- var(xbm)
    }
    sdboot_b[b] &lt;- sd(Tboot_bm)
}

z_star &lt;- (Tboot_b - Tn)/sdboot_b

hist(z_star)</code></pre>
<p><img src="Notas-Curso-Estadistica_files/figure-html/unnamed-chunk-103-1.svg" width="70%" style="display: block; margin: auto;" /></p>
<div class="sourceCode" id="cb76"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb76-1"><a href="jacknife-y-bootstrap.html#cb76-1" aria-hidden="true" tabindex="-1"></a><span class="fu">c</span>(Tn <span class="sc">-</span> <span class="fu">quantile</span>(z_star, <span class="dv">1</span> <span class="sc">-</span> <span class="fl">0.05</span><span class="sc">/</span><span class="dv">2</span>) <span class="sc">*</span> sdboot, Tn <span class="sc">-</span> </span>
<span id="cb76-2"><a href="jacknife-y-bootstrap.html#cb76-2" aria-hidden="true" tabindex="-1"></a>    <span class="fu">quantile</span>(z_star, <span class="fl">0.05</span><span class="sc">/</span><span class="dv">2</span>) <span class="sc">*</span> sdboot)</span></code></pre></div>
<pre><code>##    97.5%     2.5% 
## 314.9127 710.0993</code></pre>
<pre class="```"><code>

### Resumiendo


Resumiendo todos lo métodos de cálculo de intervalos obtenemos


```r
knitr::kable(data.frame(Metodo = c(&quot;Jacknife&quot;, &quot;Bootstrap Normal&quot;, 
    &quot;Bootstrap Pivotal&quot;, &quot;Bootstrap Pivotal Estudentizado&quot;), 
    Inferior = c(Tjack - z * sdjack/sqrt(n), Tn - z * 
        sdboot, 2 * Tn - quantile(Tboot_b, 1 - 0.05/2), 
        Tn - quantile(z_star, 1 - 0.05/2) * sdboot), 
    Superior = c(Tjack + z * sdjack/sqrt(n), Tn + z * 
        sdboot, 2 * Tn - quantile(Tboot_b, 0.05/2), 
        Tn - quantile(z_star, 0.05/2) * sdboot)))</code></pre>
<table>
<thead>
<tr class="header">
<th align="left">Metodo</th>
<th align="right">Inferior</th>
<th align="right">Superior</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Jacknife</td>
<td align="right">285.1679</td>
<td align="right">573.3289</td>
</tr>
<tr class="even">
<td align="left">Bootstrap Normal</td>
<td align="right">284.8070</td>
<td align="right">573.6898</td>
</tr>
<tr class="odd">
<td align="left">Bootstrap Pivotal</td>
<td align="right">258.6387</td>
<td align="right">555.6155</td>
</tr>
<tr class="even">
<td align="left">Bootstrap Pivotal Estudentizado</td>
<td align="right">314.9127</td>
<td align="right">710.0993</td>
</tr>
</tbody>
</table>
</div>
<div id="ejercicios-1" class="section level2" number="3.4">
<h2><span class="header-section-number">3.4</span> Ejercicios</h2>
<ol style="list-style-type: decimal">
<li><p>Repita los ejercicios anteriores para calcular intervalos de confianza para la distancia promedio y la varianza del desplazamiento de las personas. Use los métodos de Jacknife y Bootstrap (con todos sus intervalos de confianza).
Dada que la distancia es una medida que puede ser influenciada por distancias muy cortas o muy largas, se puede calcular el logaritmo de esta variable para eliminar la escala de la distancias.</p></li>
<li><p>Verifique que esta última variable se podría estimar paramétricamente con una distribución normal.
Repita los cálculos anteriores tomando como cuantiles los de una normal con media 0 y varianza 1.</p></li>
<li><p>Compare los intervalos calculados y comente los resultados.</p></li>
<li><p>Del libro <span class="citation">(<a href="análisis-en-componentes-principales.html#ref-Wasserman2006" role="doc-biblioref">Wasserman 2006</a>)</span> <strong>Sección 3:</strong> 2, 3, 7, 9, 11.</p></li>
</ol>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="estimación-de-densidades.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="estimación-de-densidades-con-bayes.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/maikol-solis/notas-curso-estadistica/edit/master/02-jacknife-bootstrap.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": "https://github.com/maikol-solis/notas-curso-estadistica/blob/master/02-jacknife-bootstrap.Rmd",
"text": null
},
"download": ["Notas-Curso-Estadistica.pdf"],
"toc": {
"collapse": "subsection"
},
"toc_depth": 5
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
